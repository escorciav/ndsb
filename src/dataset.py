import glob
import os
import tempfile

import caffe
import numpy as np
from skimage.color import gray2rgb
from skimage.io import imread, imsave
from skimage.transform import resize, rotate
from skimage.util import pad
from sklearn.cross_validation import StratifiedKFold

#TODO: Create a tuple with (img_list, img_labels) for create_val_set and
#      save_augmented_dataset

def balanced_dataset(img_labels, min_samples=500):
    """
    Return a list with indexes to augment the dataset such that categories with
    few examples get a minimum number of samples
    """
    instances_per_cat = samples_per_categories(img_labels)
    labels_array, idx = np.array(img_labels), []
    for i, v in enumerate(instances_per_cat):
        idx_cat_i = np.nonzero(labels_array == i)[0]
        ntimes = int(np.ceil(min_samples*1.0/idx_cat_i.size))
        idx += np.tile(idx_cat_i, ntimes).tolist()[:min_samples]
    return idx

def balanced_partition(img_labels, pctg=0.3):
    """
    Return two list of indexes which combined form the whole training set.
    This function creates a balanced validation set

    TODO
    ----
    1. Include argument to set seed for pseudo-random number generation
    """
    instances_per_cat = samples_per_categories(img_labels)
    instances_to_sample = int(pctg * min(instances_per_cat))
    assert instances_to_sample >= 0, 'Insufficient data to create partition'

    labels_array, idx_train, idx_test = np.array(img_labels), [], []
    for i in range(0, len(instances_per_cat)):
        idx_cat_i = np.nonzero(labels_array == i)[0]
        samples = np.random.choice(idx_cat_i, size=instances_to_sample,
                                   replace=False).tolist()
        idx_test += samples
        idx_train += list(set(idx_cat_i.tolist()) - set(samples))
    return idx_train, idx_test

def data_augmentation(img_name, angles=[], max_pixel=0, prefix=''):
    """Create many images from one training sample
    """
    n_images, img_list = len(angles), []
    img = imread(img_name)
    for th in angles:
        new_img = rotate(img, th, cval=1.0, resize=True)
        new_img = resize(new_img, (max_pixel, max_pixel))
        img_list.append(prefix + '_' + str(th) +  '.jpg')
        imsave(img_list[-1], new_img)
    return img_list

def folder_content1(folder, sort_flg=True):
    """Return all files on the first level of a folder
    """
    content = glob.glob(os.path.join(folder, '*'))
    if sort_flg:
        content.sort(key=str.lower)
    return content

def get_mean_from_protobin(filename):
    """Get image mean from protobinary and return ndarray with skimage format.
    """
    img = read_caffe_protobin(filename)
    size = (img.channels, img.height, img.width)
    img = caffe.io.blobproto_to_array(img).reshape(size)
    img = img.transpose([1, 2, 0])
    return img

def img_resolution_list(image_list):
    """Return a ndarray with the resolution (along axis 1) of a list of images
    """
    res_list = np.empty((len(image_list), 2), np.int32)
    for i, v in enumerate(image_list):
        try:
            img = imread(v)
        except:
            raise 'Cannot read image:', v
        res_list[i, :] = img.shape
    return res_list

def label_list(folder):
    """
    Return categories inside the passed folder
    
    Parameters
    ----------
    folder : string

    Returns
    -------
    labels : list

    Note
    ----
    It assumes that folder has a 1to1 mapping between subfolders and categories
    and there is no more files
    """
    labels = folder_content1(folder)
    for i, v in enumerate(labels):
        dummy, labels[i] = os.path.split(v)
    return labels

def read_caffe_protobin(filename):
    """Read protobinary generated by caffe
    """
    blob = caffe.proto.caffe_pb2.BlobProto()
    with open(filename, 'rb') as fid:
        blob.ParseFromString(fid.read())
    return blob

def root_folder():
    """Returns the absolute path of the folder where data is located
    """
    root, dummy =  os.path.split(os.path.realpath(__file__))
    return os.path.join(root, '..', 'data')

def samples_per_categories(argument):
   """Compute the number of samples per category
   """
   if isinstance(argument, basestring):
       samples_per_cat = []
       labels = folder_content1(argument)
       for i in labels:
           samples_per_cat.append(len(folder_content1(i, False)))
   else:
       samples_per_cat = np.bincount(argument).tolist()
   return samples_per_cat

def save_augmented_dataset(img_list, img_labels, outdir,
                           prm={'angles':range(0, 181, 30), 'max_pixel':60}):
    """
    Create a folder with the augmented training set

    Parameters
    ----------
    outdir : string
        Name of folder to allocate augmented training set
    prm : dict
        parameters for data augmentation function

    """
    try:
        os.makedirs(outdir)
    except Exception, e:
        raise e
    dataset_list, dataset_labels = [], []
    for (fullpath, label) in zip(img_list, img_labels):
        with tempfile.NamedTemporaryFile(dir=outdir) as temp:
            prefix = temp.name + '_' + str(label)
        aug_img = data_augmentation(fullpath, prefix=prefix, **prm)
        dataset_list += aug_img
        dataset_labels += [label] * len(aug_img)
    return dataset_list, dataset_labels

def save_augmented_test_set(img_list, outdir, max_pixel=60, crop_size=48):
    """Create a folder with the augmented training set
    """
    try:
        os.makedirs(outdir)
    except Exception, e:
        raise e

    dataset_list = []
    for i in img_list:
        filename = os.path.splitext(os.path.basename(i))[0]
        img = gray2rgb(resize(imread(i), (max_pixel, max_pixel)))
        img_coll = caffe.io.oversample([img], (crop_size, crop_size))
        for j in range(10):
            tmp = np.mean(img_coll[j, :, :, :], 2)
            new_img = pad(tmp, ((5,5), (5,5)), 'constant', constant_values=1.0)
            dataset_list += [os.path.join(outdir, filename +
                                          '_{0}.jpeg'.format(j))]
            imsave(dataset_list[-1], new_img)
    return dataset_list

def stratified_partition(img_labels, pctg=0.3):
    """
    Return two list of indexes which combined form the whole training set.
    This function keep the distribution of samples of the training set
    """
    assert pctg<=0.5, 'Invalid percentage. It must be <= 0.5'

    skf = StratifiedKFold(img_labels, n_folds=np.ceil(1/pctg), shuffle=True)
    idx = skf.test_folds == 0
    idx_test =  np.nonzero(idx)[0].tolist()
    idx_train = np.nonzero(1 - idx)[0].tolist()
    return idx_train, idx_test

def test_folder():
    """Returns the absolute path of the train folder
    """
    root = root_folder()
    return os.path.join(root, 'test')

def test_list(folder):
    """Return a list with fullpath name of images on the testing set
    """
    return folder_content1(test_folder())

def train_folder():
    """Returns the absolute path of the test folder
    """
    root = root_folder()
    return os.path.join(root, 'train')

def train_list(folder):
    """
    Return two list: (1) fullpath name of images and (2) indexes of their
    categories (0-indexed)

    Parameters
    ----------
    folder : string

    Returns
    -------
    image_fullpath_names : list
    image_labels : list

    Note
    ----
    It assumes that folder has a 1to1 mapping between subfolders and categories
    and there is no more files
    """
    image_fullpath_names, image_labels = [], []
    labels = folder_content1(folder)
    for i, v in enumerate(labels):
        tmp = folder_content1(v)
        image_fullpath_names += tmp
        image_labels += [i] * len(tmp)
    return image_fullpath_names, image_labels

